{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x640 (no detections), 1120.4ms\n",
      "Speed: 98.0ms preprocess, 1120.4ms inference, 101.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 (no detections), 252.4ms\n",
      "Speed: 9.0ms preprocess, 252.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 (no detections), 213.2ms\n",
      "Speed: 17.6ms preprocess, 213.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 (no detections), 205.0ms\n",
      "Speed: 16.1ms preprocess, 205.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 (no detections), 208.5ms\n",
      "Speed: 7.2ms preprocess, 208.5ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 (no detections), 217.4ms\n",
      "Speed: 0.0ms preprocess, 217.4ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 (no detections), 218.5ms\n",
      "Speed: 0.0ms preprocess, 218.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 199.8ms\n",
      "Speed: 0.9ms preprocess, 199.8ms inference, 171.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 217.3ms\n",
      "Speed: 0.0ms preprocess, 217.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 212.6ms\n",
      "Speed: 17.7ms preprocess, 212.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 260.4ms\n",
      "Speed: 6.0ms preprocess, 260.4ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 210.8ms\n",
      "Speed: 0.0ms preprocess, 210.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 243.2ms\n",
      "Speed: 0.0ms preprocess, 243.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 244.2ms\n",
      "Speed: 3.2ms preprocess, 244.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 214.4ms\n",
      "Speed: 0.0ms preprocess, 214.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 200.4ms\n",
      "Speed: 11.5ms preprocess, 200.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 200.2ms\n",
      "Speed: 0.0ms preprocess, 200.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 215.2ms\n",
      "Speed: 0.0ms preprocess, 215.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 202.6ms\n",
      "Speed: 15.6ms preprocess, 202.6ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 200.5ms\n",
      "Speed: 7.0ms preprocess, 200.5ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 194.2ms\n",
      "Speed: 6.0ms preprocess, 194.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 213.5ms\n",
      "Speed: 0.0ms preprocess, 213.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 201.7ms\n",
      "Speed: 6.0ms preprocess, 201.7ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 216.1ms\n",
      "Speed: 0.0ms preprocess, 216.1ms inference, 0.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 197.1ms\n",
      "Speed: 6.0ms preprocess, 197.1ms inference, 15.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 202.0ms\n",
      "Speed: 5.1ms preprocess, 202.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 206.5ms\n",
      "Speed: 6.3ms preprocess, 206.5ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 198.1ms\n",
      "Speed: 0.0ms preprocess, 198.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 215.9ms\n",
      "Speed: 4.4ms preprocess, 215.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 210.3ms\n",
      "Speed: 6.0ms preprocess, 210.3ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 197.2ms\n",
      "Speed: 6.0ms preprocess, 197.2ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 200.8ms\n",
      "Speed: 0.0ms preprocess, 200.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 234.8ms\n",
      "Speed: 13.4ms preprocess, 234.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 216.5ms\n",
      "Speed: 7.0ms preprocess, 216.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 211.7ms\n",
      "Speed: 18.6ms preprocess, 211.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 214.8ms\n",
      "Speed: 0.0ms preprocess, 214.8ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 212.5ms\n",
      "Speed: 1.1ms preprocess, 212.5ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 195.4ms\n",
      "Speed: 5.0ms preprocess, 195.4ms inference, 15.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 184.8ms\n",
      "Speed: 0.0ms preprocess, 184.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 193.8ms\n",
      "Speed: 6.0ms preprocess, 193.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 233.9ms\n",
      "Speed: 17.6ms preprocess, 233.9ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 213.0ms\n",
      "Speed: 6.4ms preprocess, 213.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 193.8ms\n",
      "Speed: 7.0ms preprocess, 193.8ms inference, 15.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 221.4ms\n",
      "Speed: 9.0ms preprocess, 221.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 201.7ms\n",
      "Speed: 6.0ms preprocess, 201.7ms inference, 15.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 200.1ms\n",
      "Speed: 0.0ms preprocess, 200.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 Personas, 220.5ms\n",
      "Speed: 14.4ms preprocess, 220.5ms inference, 12.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 3 Personas, 255.6ms\n",
      "Speed: 14.0ms preprocess, 255.6ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 251.9ms\n",
      "Speed: 0.0ms preprocess, 251.9ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 213.9ms\n",
      "Speed: 7.0ms preprocess, 213.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 202.6ms\n",
      "Speed: 4.0ms preprocess, 202.6ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 203.4ms\n",
      "Speed: 3.9ms preprocess, 203.4ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 200.0ms\n",
      "Speed: 0.0ms preprocess, 200.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 201.6ms\n",
      "Speed: 1.9ms preprocess, 201.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 200.0ms\n",
      "Speed: 0.0ms preprocess, 200.0ms inference, 11.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 224.8ms\n",
      "Speed: 5.3ms preprocess, 224.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 203.2ms\n",
      "Speed: 5.9ms preprocess, 203.2ms inference, 15.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 199.6ms\n",
      "Speed: 2.7ms preprocess, 199.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 197.8ms\n",
      "Speed: 13.1ms preprocess, 197.8ms inference, 15.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 218.0ms\n",
      "Speed: 0.0ms preprocess, 218.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 193.4ms\n",
      "Speed: 7.0ms preprocess, 193.4ms inference, 14.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 212.0ms\n",
      "Speed: 0.0ms preprocess, 212.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 204.5ms\n",
      "Speed: 9.2ms preprocess, 204.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 194.7ms\n",
      "Speed: 7.2ms preprocess, 194.7ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 282.6ms\n",
      "Speed: 11.8ms preprocess, 282.6ms inference, 5.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 201.5ms\n",
      "Speed: 0.0ms preprocess, 201.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 200.5ms\n",
      "Speed: 6.0ms preprocess, 200.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 210.6ms\n",
      "Speed: 0.0ms preprocess, 210.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 2 Personas, 199.4ms\n",
      "Speed: 6.0ms preprocess, 199.4ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import cvzone\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from tracker import *\n",
    "\n",
    "model=YOLO('datasets\\\\weights\\\\best.pt')\n",
    "#model = YOLO('yolo-Weights\\yolov8s.pt')\n",
    "\n",
    "class Color:\n",
    "    def boundingBox1(self):\n",
    "        green = (0,255,0)\n",
    "        return green\n",
    "    def boundingBox2(self):\n",
    "        yellow = (0,255,255)\n",
    "        return yellow\n",
    "    def text1(self):\n",
    "        white = (255,255,255)\n",
    "        return white\n",
    "    def text2(self):\n",
    "        black = (0,0,0)\n",
    "        return black\n",
    "    def area1(self):\n",
    "        blue = (255,0,0)\n",
    "        return blue\n",
    "    def area2(self):\n",
    "        blue = (255,0,0)\n",
    "        return blue\n",
    "    def point(self):\n",
    "        pink = (255,0,255)\n",
    "        return pink \n",
    "    def center_point(self):\n",
    "        cyan = (255,255,0)\n",
    "        return cyan\n",
    "    def rectangle(self):\n",
    "        red = (0,0,255)\n",
    "        return red\n",
    "\n",
    "color = Color()\n",
    "tracker = Tracker()\n",
    "    \n",
    "class Algorithm_Count:\n",
    "    def __init__(self, a1, a2):\n",
    "        self.people_entering = {}\n",
    "        self.entering = set()\n",
    "        self.people_exiting = {}\n",
    "        self.exiting = set()\n",
    "        self.area1 = a1\n",
    "        self.area2 = a2\n",
    "        self.paused = False\n",
    "        self.coordinates = []\n",
    "\n",
    "        cv2.namedWindow('Frame')\n",
    "        cv2.setMouseCallback('Frame', self.mouse_clicked)\n",
    "\n",
    "    def center_point(self, a, b):\n",
    "        c = int((a+b)//2)\n",
    "        return c\n",
    "\n",
    "    def detect(self, frame):\n",
    "        results = model(frame, conf=0.6, classes=[0])\n",
    "        for result in results:\n",
    "            detections = []\n",
    "            for r in result.boxes.data.tolist():\n",
    "                x1, y1, x2, y2, score, class_id = r\n",
    "                detections.append([int(x1), int(y1), int(x2), int(y2), float(score)])\n",
    "        return detections\n",
    "    \n",
    "    def draw_boxes(self, frame, detections):\n",
    "        list = []\n",
    "        for box in detections:\n",
    "            if len(box) == 5:\n",
    "                x1, y1, x2, y2, score = box\n",
    "                class_id = 0  # Default class ID for a person\n",
    "            elif len(box) == 6:\n",
    "                x1, y1, x2, y2, score, class_id = box\n",
    "            else: continue  # Skip boxes with unexpected length\n",
    "\n",
    "            if class_id == 0:  # Assuming person class is 0\n",
    "                label1 = f\"Person: {score:.2f}\"\n",
    "                list.append([x1, y1, x2, y2])\n",
    "                \n",
    "                \n",
    "                cx2 = self.center_point(x1, x2)\n",
    "                cy2 = self.center_point(y1, y2)\n",
    "                #cv2.circle(frame, (cx2, cy2), 4, color.center_point(), -1)\n",
    "                \n",
    "                \n",
    "                \n",
    "        bbox_id = tracker.update(list)\n",
    "        for bbox in bbox_id:\n",
    "            x3, y3, x4, y4, id = bbox\n",
    "            cx = self.center_point(x3, x3) # may mali\n",
    "            cy = self.center_point(y3, y4)\n",
    "            label2 = f\"{id} Person: {score:.2f}\"\n",
    "\n",
    "            if id != -1:\n",
    "                cv2.rectangle(frame, (x3, y3), (x4, y4), color.rectangle(), 2)\n",
    "                #cvzone.putTextRect(frame, label2, (x3+10, y3-10), 1,1, color.text1(), color.text2()) \n",
    "\n",
    "            # People going right\n",
    "            result_p1 = cv2.pointPolygonTest(np.array(self.area2,np.int32), ((x4,y4)), False)\n",
    "            result_c1 = cv2.pointPolygonTest(np.array(self.area2,np.int32), ((cx,cy)), False)\n",
    "            if result_p1 >= 0 or result_c1 >= 0:\n",
    "                self.people_entering[id] = ((x4, y4), (cx, cy)) \n",
    "                cv2.rectangle(frame, (x3, y3), (x4, y4), color.boundingBox2(), 2)\n",
    "                cvzone.putTextRect(frame, label2, (x3+10, y3-10), 1,1, color.text1(), color.text2()) \n",
    "                #cv2.putText(frame, label2, (x3, y3 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color.text1(), 2)\n",
    "            if id in self.people_entering:\n",
    "                result_p2 = cv2.pointPolygonTest(np.array(self.area1,np.int32), ((x4,y4)), False)\n",
    "                result_c2 = cv2.pointPolygonTest(np.array(self.area1,np.int32), ((cx,cy)), False)\n",
    "                if result_p2 >= 0 or result_c2 >= 0:\n",
    "                    cv2.rectangle(frame, (x3, y3), (x4, y4), color.boundingBox1(), 2)\n",
    "                    cv2.circle(frame, (x4, y4), 4, color.point(), -1)  \n",
    "                    #cv2.putText(frame, label2, (x3, y3 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color.text1(), 2)\n",
    "                    cvzone.putTextRect(frame, label2, (x3+10, y3-10), 1,1, color.text1(), color.text2())\n",
    "                    self.entering.add(id)\n",
    "            # People going left\n",
    "            result_p3 = cv2.pointPolygonTest(np.array(self.area1,np.int32), ((x4,y4)), False)\n",
    "            result_c3 = cv2.pointPolygonTest(np.array(self.area2,np.int32), ((cx,cy)), False)\n",
    "            if result_p3 >= 0 or result_c3 >= 0:\n",
    "                self.people_exiting[id] = ((x4, y4), (cx, cy)) \n",
    "                cv2.rectangle(frame, (x3, y3), (x4, y4), color.boundingBox1(), 2)\n",
    "                cvzone.putTextRect(frame, label2, (x3+10, y3-10), 1,1, color.text1(), color.text2()) \n",
    "            if id in self.people_exiting:\n",
    "                result_p4 = cv2.pointPolygonTest(np.array(self.area2,np.int32), ((x4,y4)), False)\n",
    "                result_c4 = cv2.pointPolygonTest(np.array(self.area2,np.int32), ((cx,cy)), False)  \n",
    "                if result_p4 >= 0 or result_c4 >= 0:\n",
    "                    cv2.rectangle(frame, (x3, y3), (x4, y4), color.boundingBox2(), 2)\n",
    "                    cv2.circle(frame, (x4, y4), 4, color.point(), -1)  \n",
    "                    #cv2.putText(frame, label2, (x3, y3 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color.text1(), 2)\n",
    "                    cvzone.putTextRect(frame, label2, (x3+10, y3-10), 1,1, color.text1(), color.text2())\n",
    "                    self.exiting.add(id)\n",
    "\n",
    "        cv2.polylines(frame,[np.array(self.area1,np.int32)],True,color.area1(),2)\n",
    "        cv2.putText(frame,str('1'),(504,471),cv2.FONT_HERSHEY_COMPLEX,(0.5),color.text2(),1)\n",
    "\n",
    "        cv2.polylines(frame,[np.array(self.area2,np.int32)],True,color.area2(),2)\n",
    "        cv2.putText(frame,str('2'),(466,485),cv2.FONT_HERSHEY_COMPLEX,(0.5),color.text2(),1)\n",
    "        enter = len(self.entering)\n",
    "        exit = len(self.exiting)\n",
    "\n",
    "        #cv2.putText(frame,str(f'Enter: {enter}'),(60,80),cv2.FONT_HERSHEY_COMPLEX,(0.7),color.text1(),2)\n",
    "        #cv2.putText(frame,str(f'Exit: {exit}'),(60,148),cv2.FONT_HERSHEY_COMPLEX,(0.7),color.text1(),2)\n",
    "        cvzone.putTextRect(frame,str(f\"Enter: {enter}\"), (20,30), 1,1, color.text1(), color.text2())\n",
    "        cvzone.putTextRect(frame,str(f\"Exit: {exit}\"), (20,60), 1,1, color.text1(), color.text2())\n",
    "\n",
    "        \n",
    "        #cvzone.putTextRect(frame,str(f\"Exit: {exit}\"), (20,60), 1,1, color.text1(), color.text2())\n",
    "        \n",
    "        \n",
    "        #print(self.people_entering)\n",
    "\n",
    "    def mouse_clicked(self, event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN :\n",
    "            # Clear the list and append new clicked coordinates\n",
    "            self.coordinates.clear()\n",
    "            self.coordinates.append((x, y))\n",
    "\n",
    "    def show_coordinates(self, frame):\n",
    "        # Display clicked coordinates\n",
    "        for coords in self.coordinates:\n",
    "            #coordinates = f'Coordinates: {coords}'\n",
    "            x, y = coords\n",
    "            cvzone.putTextRect(frame,str(f\"X: {x}, Y: {y}\"), (120,30), 1,1, color.text1(), color.text2())\n",
    "\n",
    "    def counting(self, video_path):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        downloads_path = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
    "        output_file_path = os.path.join(downloads_path, 'output_video.avi')\n",
    "        out = cv2.VideoWriter(output_file_path,cv2.VideoWriter_fourcc(*'XVID'), 24.0, (1020,500))\n",
    "\n",
    "        while True:\n",
    "            if not self.paused:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret: break\n",
    "\n",
    "                frame = cv2.resize(frame,(1020,500))\n",
    "\n",
    "                #results = model.track(frame, persist=True, conf=0.5)\n",
    "                #frame_ = results[0].plot()\n",
    "\n",
    "                detections = self.detect(frame)\n",
    "                self.draw_boxes(frame, detections)\n",
    "                self.show_coordinates(frame)\n",
    "\n",
    "\n",
    "                out.write(frame)\n",
    "                cv2.imshow('Frame', frame)\n",
    "\n",
    "            key = cv2.waitKey(1)&0xFF\n",
    "            if key == ord('q') or cv2.getWindowProperty('Frame', cv2.WND_PROP_VISIBLE) < 1: \n",
    "                break\n",
    "            elif key == ord('p'):\n",
    "                self.paused = not self.paused\n",
    "\n",
    "\n",
    "            #if cv2.waitKey()&0xFF == ord('q'): break\n",
    "            #if cv2.waitKey(0)&0xFF == 27: continue\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "a1=[(312,388),(289,390),(474,469),(497,462)]\n",
    "a2=[(279,392),(250,397),(423,477),(454,469)]\n",
    "#a1 = [(642,371), (626,372), (661,431), (666,413)] \n",
    "#a2 = [(610,364), (592,366), (628,435), (644,432)]\n",
    "\n",
    "in_video_path = 'Sample Test File\\\\test_video.mp4'\n",
    "\n",
    "algo = Algorithm_Count(a1, a2)\n",
    "\n",
    "\n",
    "algo.counting(in_video_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
