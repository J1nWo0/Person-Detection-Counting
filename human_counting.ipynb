{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x640 (no detections), 1197.5ms\n",
      "Speed: 168.3ms preprocess, 1197.5ms inference, 52.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 (no detections), 204.5ms\n",
      "Speed: 0.0ms preprocess, 204.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 (no detections), 705.5ms\n",
      "Speed: 6.0ms preprocess, 705.5ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 (no detections), 269.8ms\n",
      "Speed: 7.0ms preprocess, 269.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 (no detections), 295.2ms\n",
      "Speed: 7.0ms preprocess, 295.2ms inference, 16.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 (no detections), 258.6ms\n",
      "Speed: 7.0ms preprocess, 258.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 (no detections), 207.7ms\n",
      "Speed: 2.3ms preprocess, 207.7ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "WARNING  NMS time limit 0.550s exceeded\n",
      "0: 320x640 1 Persona, 181.7ms\n",
      "Speed: 5.0ms preprocess, 181.7ms inference, 2207.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 97.2ms\n",
      "Speed: 2.0ms preprocess, 97.2ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 94.2ms\n",
      "Speed: 0.0ms preprocess, 94.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 106.0ms\n",
      "Speed: 0.0ms preprocess, 106.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 85.7ms\n",
      "Speed: 2.0ms preprocess, 85.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 174.5ms\n",
      "Speed: 0.0ms preprocess, 174.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 172.2ms\n",
      "Speed: 5.0ms preprocess, 172.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 177.5ms\n",
      "Speed: 0.0ms preprocess, 177.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 185.1ms\n",
      "Speed: 0.0ms preprocess, 185.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 183.4ms\n",
      "Speed: 7.0ms preprocess, 183.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 193.8ms\n",
      "Speed: 0.0ms preprocess, 193.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 Persona, 192.7ms\n",
      "Speed: 0.0ms preprocess, 192.7ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import cvzone\n",
    "import time\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from tracker import *\n",
    "\n",
    "model=YOLO('datasets\\\\weights\\\\best.pt')\n",
    "#model = YOLO('yolo-Weights\\yolov8s.pt')\n",
    "\n",
    "class Color:\n",
    "    def boundingBox1(self):\n",
    "        green = (0,255,0)\n",
    "        return green\n",
    "    def boundingBox2(self):\n",
    "        yellow = (0,255,255)\n",
    "        return yellow\n",
    "    def text1(self):\n",
    "        white = (255,255,255)\n",
    "        return white\n",
    "    def text2(self):\n",
    "        black = (0,0,0)\n",
    "        return black\n",
    "    def area1(self):\n",
    "        blue = (255,0,0)\n",
    "        return blue\n",
    "    def area2(self):\n",
    "        red = (0, 0, 255)\n",
    "        return red\n",
    "    def point(self):\n",
    "        pink = (255,0,255)\n",
    "        return pink \n",
    "    def center_point(self):\n",
    "        cyan = (255,255,0)\n",
    "        return cyan\n",
    "    def rectangle(self):\n",
    "        orange = (0,119,255)\n",
    "        return orange\n",
    "\n",
    "color = Color()\n",
    "tracker = Tracker()\n",
    "    \n",
    "class Algorithm_Count:\n",
    "    def __init__(self, a1, a2):\n",
    "        self.people_entering = {}\n",
    "        self.entering = set()\n",
    "        self.people_exiting = {}\n",
    "        self.exiting = set()\n",
    "        self.area1 = a1\n",
    "        self.area2 = a2\n",
    "        self.paused = False\n",
    "        self.coordinates = []\n",
    "        self.start_time = time.time()\n",
    "\n",
    "        cv2.namedWindow('Frame')\n",
    "\n",
    "    def center_point(self, a, b):\n",
    "        c = int((a+b)//2)\n",
    "        return c\n",
    "\n",
    "    def detect(self, frame):\n",
    "        results = model(frame, conf=0.6, classes=[0])\n",
    "        for result in results:\n",
    "            detections = []\n",
    "            for r in result.boxes.data.tolist():\n",
    "                x1, y1, x2, y2, score, class_id = r\n",
    "                detections.append([int(x1), int(y1), int(x2), int(y2), float(score)])\n",
    "        return detections\n",
    "    \n",
    "    def draw_boxes(self, frame, detections):\n",
    "        list = []\n",
    "        for box in detections:\n",
    "            if len(box) == 5:\n",
    "                x1, y1, x2, y2, score = box\n",
    "                class_id = 0  # Default class ID for a person\n",
    "            elif len(box) == 6:\n",
    "                x1, y1, x2, y2, score, class_id = box\n",
    "            else: continue  # Skip boxes with unexpected length\n",
    "\n",
    "            if class_id == 0:  # Assuming person class is 0\n",
    "                label1 = f\"Person: {score:.2f}\"\n",
    "                list.append([x1, y1, x2, y2])\n",
    "                \n",
    "                \n",
    "                cx2 = self.center_point(x1, x2)\n",
    "                cy2 = self.center_point(y1, y2)\n",
    "                #cv2.circle(frame, (cx2, cy2), 4, color.center_point(), -1)\n",
    "                \n",
    "        bbox_id = tracker.update(list)\n",
    "        for bbox in bbox_id:\n",
    "            x3, y3, x4, y4, id = bbox\n",
    "            cx = self.center_point(x3, x3) # ! may mali dapat x4\n",
    "            cy = self.center_point(y3, y4)\n",
    "            label2 = f\"{id} Person: {score:.2f}\"\n",
    "\n",
    "            if id != -1:\n",
    "                cv2.rectangle(frame, (x3, y3), (x4, y4), color.rectangle(), 2)\n",
    "                #cvzone.putTextRect(frame, label2, (x3+10, y3-10), 1,1, color.text1(), color.text2()) \n",
    "\n",
    "            # People going right\n",
    "            result_p1 = cv2.pointPolygonTest(np.array(self.area2,np.int32), ((x4,y4)), False)\n",
    "            result_c1 = cv2.pointPolygonTest(np.array(self.area2,np.int32), ((cx,cy)), False)\n",
    "            if result_p1 >= 0 or result_c1 >= 0:\n",
    "                self.people_entering[id] = ((x4, y4), (cx, cy)) \n",
    "                cv2.rectangle(frame, (x3, y3), (x4, y4), color.boundingBox2(), 2)\n",
    "                cvzone.putTextRect(frame, label2, (x3+10, y3-10), 1,1, color.text1(), color.text2()) \n",
    "                #cv2.putText(frame, label2, (x3, y3 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color.text1(), 2)\n",
    "            if id in self.people_entering:\n",
    "                result_p2 = cv2.pointPolygonTest(np.array(self.area1,np.int32), ((x4,y4)), False)\n",
    "                result_c2 = cv2.pointPolygonTest(np.array(self.area1,np.int32), ((cx,cy)), False)\n",
    "                if result_p2 >= 0 or result_c2 >= 0:\n",
    "                    cv2.rectangle(frame, (x3, y3), (x4, y4), color.boundingBox1(), 2)\n",
    "                    cv2.circle(frame, (x4, y4), 4, color.point(), -1)  \n",
    "                    #cv2.putText(frame, label2, (x3, y3 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color.text1(), 2)\n",
    "                    cvzone.putTextRect(frame, label2, (x3+10, y3-10), 1,1, color.text1(), color.text2())\n",
    "                    self.entering.add(id)\n",
    "            # People going left\n",
    "            result_p3 = cv2.pointPolygonTest(np.array(self.area1,np.int32), ((x4,y4)), False)\n",
    "            result_c3 = cv2.pointPolygonTest(np.array(self.area2,np.int32), ((cx,cy)), False)\n",
    "            if result_p3 >= 0 or result_c3 >= 0:\n",
    "                self.people_exiting[id] = ((x4, y4), (cx, cy)) \n",
    "                cv2.rectangle(frame, (x3, y3), (x4, y4), color.boundingBox1(), 2)\n",
    "                cvzone.putTextRect(frame, label2, (x3+10, y3-10), 1,1, color.text1(), color.text2()) \n",
    "            if id in self.people_exiting:\n",
    "                result_p4 = cv2.pointPolygonTest(np.array(self.area2,np.int32), ((x4,y4)), False)\n",
    "                result_c4 = cv2.pointPolygonTest(np.array(self.area2,np.int32), ((cx,cy)), False)  \n",
    "                if result_p4 >= 0 or result_c4 >= 0:\n",
    "                    cv2.rectangle(frame, (x3, y3), (x4, y4), color.boundingBox2(), 2)\n",
    "                    cv2.circle(frame, (x4, y4), 4, color.point(), -1)  \n",
    "                    #cv2.putText(frame, label2, (x3, y3 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color.text1(), 2)\n",
    "                    cvzone.putTextRect(frame, label2, (x3+10, y3-10), 1,1, color.text1(), color.text2())\n",
    "                    self.exiting.add(id)\n",
    "\n",
    "        cv2.polylines(frame,[np.array(self.area1,np.int32)],True,color.area1(),2)\n",
    "        #cvzone.putTextRect(frame,str('1'), (self.area1[3][0]+5, self.area1[3][1]+2), 1,1, color.text1(), color.text2())\n",
    "\n",
    "        cv2.polylines(frame,[np.array(self.area2,np.int32)],True,color.area2(),2)\n",
    "        #cvzone.putTextRect(frame,str('2'), (self.area2[3][0]+5, self.area2[3][1]+2), 1,1, color.text1(), color.text2())\n",
    "        enter = len(self.entering)\n",
    "        exit = len(self.exiting)\n",
    "        cvzone.putTextRect(frame,str(f\"Enter: {enter}\"), (20,30), 1,1, color.text1(), color.text2())\n",
    "        cvzone.putTextRect(frame,str(f\"Exit: {exit}\"), (20,60), 1,1, color.text1(), color.text2())\n",
    "\n",
    "    def show_time(self, frame):\n",
    "        elapsed_time = time.time() - self.start_time\n",
    "\n",
    "        # Convert elapsed time to hours, minutes, seconds, and milliseconds\n",
    "        milliseconds = int(elapsed_time * 1000) / 11\n",
    "        hours, milliseconds = divmod(milliseconds, 3600000)\n",
    "        minutes, milliseconds = divmod(milliseconds, 60000)\n",
    "        seconds = milliseconds / 1000.0\n",
    "\n",
    "        # Display the time in the format \"hour:minute:second.millisecond\"\n",
    "        time_str = \"Time: {:02}:{:02}:{:06.3f}\".format(int(hours), int(minutes), seconds)\n",
    "        cvzone.putTextRect(frame,time_str, (20,480), 1,1, color.text1(), color.text2())\n",
    "\n",
    "    def counting(self, video_path):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        downloads_path = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
    "        output_file_path = os.path.join(downloads_path, 'output_video.avi')\n",
    "        out = cv2.VideoWriter(output_file_path,cv2.VideoWriter_fourcc(*'XVID'), 24.0, (1020,500))\n",
    "\n",
    "        while True:\n",
    "            if not self.paused:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret: break\n",
    "\n",
    "                frame = cv2.resize(frame,(1020,500))\n",
    "\n",
    "                #results = model.track(frame, persist=True, conf=0.5)\n",
    "                #frame_ = results[0].plot()\n",
    "\n",
    "                detections = self.detect(frame)\n",
    "                self.draw_boxes(frame, detections)\n",
    "                self.show_time(frame)\n",
    "\n",
    "\n",
    "                out.write(frame)\n",
    "                cv2.imshow('Frame', frame)\n",
    "\n",
    "            key = cv2.waitKey(1)&0xFF\n",
    "            if key == ord('q') or cv2.getWindowProperty('Frame', cv2.WND_PROP_VISIBLE) < 1: \n",
    "                break\n",
    "            elif key == ord('p'):\n",
    "                self.paused = not self.paused\n",
    "\n",
    "\n",
    "            #if cv2.waitKey()&0xFF == ord('q'): break\n",
    "            #if cv2.waitKey(0)&0xFF == 27: continue\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "a1=[(312,388),(289,390),(474,469),(497,462)]\n",
    "a2=[(279,392),(250,397),(423,477),(454,469)]\n",
    "#a1 = [(642,371), (626,372), (661,431), (666,413)] \n",
    "#a2 = [(610,364), (592,366), (628,435), (644,432)]\n",
    "\n",
    "in_video_path = 'Sample Test File\\\\test_video.mp4'\n",
    "\n",
    "algo = Algorithm_Count(a1, a2)\n",
    "\n",
    "\n",
    "algo.counting(in_video_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
